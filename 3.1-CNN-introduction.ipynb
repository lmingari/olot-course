{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337805be-39ec-4dc6-8ead-8b7e382402b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install requirements\n",
    "from os.path import isfile\n",
    "\n",
    "repository   = \"https://github.com/lmingari/olot-course.git\"\n",
    "requirements = \"requirements-section3-1.txt\"\n",
    "\n",
    "if not isfile(requirements):\n",
    "    !git clone {repository}\n",
    "    %cd olot-course\n",
    "    !pip install -r {requirements}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f522a-f9f5-4597-b2a4-9dcfc449ed24",
   "metadata": {},
   "source": [
    "# 3.1 Convolutional neural networks (CNN)\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbeabfa-1f0e-4645-a9a5-666fe816cd01",
   "metadata": {},
   "source": [
    "* __Multilayer perceptron__\n",
    "  - Input features are assumed to be _independent_ (e.g. $x_1 \\leftrightarrow x_3$)\n",
    "  - There is no assumption about dependence between input features\n",
    "  - Ideal for tabular datasets\n",
    "* __Convolutional neural networks__\n",
    "  - _Locality_ assumption\n",
    "  - Widely used for image analysis (neighbouring pixels are related to each other)\n",
    "  - Make training more efficient\n",
    "  - Capture feature dependency and extract local features\n",
    "\n",
    "| A multilayer perceptron |\n",
    "| ----------------------- |\n",
    "| <img src=\"figs/mlp.svg\" width=500 /> |\n",
    "| __Figure 1:__ A multilayer perceptron |\n",
    "\n",
    "| A convolutional neural network |\n",
    "| -------------------------- |\n",
    "| ![](figs/cnn.svg) |\n",
    "| __Figure 2:__ A typical CNN arquitecture with two convolution layers |\n",
    "\n",
    "[convnet]: https://docs.pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65dea30-93e4-430f-b4cc-9d09f8d1bfc3",
   "metadata": {},
   "source": [
    "## Illustration of 2D-Convolution Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e20647-c7a3-49c0-a07b-9d6a6ea5157c",
   "metadata": {},
   "source": [
    "* Technique to extract features from the given input\n",
    "* The filter coefficients and thus the relevant features are learned\n",
    "\n",
    "<div style=\"width: 460px;\">\n",
    "\n",
    "| A 2D convolution with a 3x3 kernel |\n",
    "| ---------------------------------- |\n",
    "| ![](figs/convolution.webp) |\n",
    "| __Figure 3__: Convolution is applied on the input data using a 3x3 filter to produce a feature map. The filter or kernel is represented by the red square moving over the input image. |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6021fc49-d833-4304-b4e7-43ca8c74c757",
   "metadata": {},
   "source": [
    "## Implementing a simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd409d08-ea1f-4f71-8841-69762be2c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb1c157-95fe-4a15-99ad-43fc0ba77523",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implement the CNN architecture of Fig. 2\n",
    "class ConvolutionalNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, padding=1, stride=2), \n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(in_channels=6, out_channels=12, kernel_size=3, padding=1, stride=2), \n",
    "            nn.ReLU(True),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(12*8*8,3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.cnn(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49278f-d665-4c9e-886a-1e8223f942cf",
   "metadata": {},
   "source": [
    "Formula for output dims calculation in a Conv2d layer:\n",
    "\n",
    "$$ n_{out} = \\lfloor \\dfrac{n_{in} + 2p - k}{s} \\rfloor + 1$$\n",
    "\n",
    "* k: convolution kernel size\n",
    "* p: convolution padding size\n",
    "* s: convolution stride size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1065fa87-0d17-43c7-83b9-52909b6b7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvolutionalNet()\n",
    "summary(model, (1,32,32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb2f17-73d4-4e73-9a33-6b105041fef1",
   "metadata": {},
   "source": [
    "## Convolutional Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a654de-0f4d-49e9-8771-9b34653347f2",
   "metadata": {},
   "source": [
    "* Autoencoders are a type of artificial neural network used primarily for unsupervised learning.\n",
    "* Designed to compress input data into a condensed set of representations and then reconstruct the input from these representations minimal information loss:\n",
    "  1. Encoder\n",
    "  2. Decoder\n",
    "\n",
    "| Autoencoder diagram |\n",
    "| ---- |\n",
    "| ![](figs/autoencoder.svg) |\n",
    "| __Figure 4__: Autoencoders are a type of artificial neural network used primarily for unsupervised learning  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb8120-948b-43f4-b7e1-b99f5cd47e35",
   "metadata": {},
   "source": [
    "#### Examples of some applications\n",
    "\n",
    "  -  denoising\n",
    "  -  dimensionality reduction\n",
    "  -  anomaly detection\n",
    "\n",
    "<div style=\"width: 600px;\">\n",
    "    \n",
    "| Reducing the Dimensionality of Data with Neural Networks |\n",
    "| --- |\n",
    "| ![](figs/hinton.png) |\n",
    "| __Figure 5__: G. E. Hinton, R. R. Salakhutdinov, Reducing the Dimensionality of Data with Neural Networks. _Science_ __313__, 504-507 (2006). DOI: [10.1126/science.1127647][doi] |\n",
    "\n",
    "| Super-resolution reconstruction of brain MRIs |\n",
    "| --- |\n",
    "|![][brain] |\n",
    "| __Figure 6__: Super-resolution reconstruction of brain magnetic resonance images via lightweight autoencoder. Extracted from [Andrew et al. (2021)][brain-doi] |\n",
    "\n",
    "| Downscaling meteorological data |\n",
    "| --- |\n",
    "| ![][era5] |\n",
    "| __Figure 7__: Downscaling based on deep learning applied to meteorological data. Extracted from [Tomasi et al. (2025)][era5-doi]|\n",
    "\n",
    "</div>\n",
    "\n",
    "[doi]: https://doi.org/10.1126/science.1127647\n",
    "[era5]: https://gmd.copernicus.org/articles/18/2051/2025/gmd-18-2051-2025-f03-web.jpg\n",
    "[era5-doi]: https://doi.org/10.5194/gmd-18-2051-2025\n",
    "[brain]: https://ars.els-cdn.com/content/image/1-s2.0-S2352914821001945-gr4_lrg.jpg\n",
    "[brain-doi]: https://doi.org/10.1016/j.imu.2021.100713"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
